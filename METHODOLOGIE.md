# üìù Notes M√©thodologiques et Justifications

## Document de r√©f√©rence pour la soutenance du projet

---

## 1. Choix M√©thodologiques Cl√©s

### 1.1 Traitement des Valeurs Manquantes

#### Strat√©gie adopt√©e:
- **Variables num√©riques**: Imputation par la **m√©diane**
- **Variables cat√©gorielles**: Imputation par le **mode**
- **Variables de satisfaction avec 'NA' textuel**: Conversion en NaN puis imputation m√©diane

#### Justification:
‚úÖ **M√©diane vs Moyenne**: La m√©diane est plus robuste aux outliers, particuli√®rement important pour des variables comme MonthlyIncome ou Age qui peuvent avoir des valeurs extr√™mes.

‚úÖ **Pas de suppression de lignes**: Avec seulement ~4000 observations et un taux d'attrition de 15%, chaque observation compte. Supprimer des lignes r√©duirait la puissance statistique.

‚úÖ **Traitement des 'NA' textuels**: Les 'NA' dans employee_survey_data sont des non-r√©ponses volontaires, pas des donn√©es manquantes techniques. L'imputation par la m√©diane √©vite de cr√©er un biais (la m√©diane repr√©sente une "satisfaction neutre").

#### Alternatives consid√©r√©es (et √©cart√©es):
‚ùå **Imputation par r√©gression**: Trop complexe et risque d'overfitting
‚ùå **Suppression listwise**: Perte de puissance statistique
‚ùå **MICE (Multiple Imputation)**: Temps de calcul excessif pour ce contexte

---

### 1.2 Encodage des Variables Cat√©gorielles

#### Strat√©gie adopt√©e:
- **Label Encoding** pour variables ordinales (Education, JobSatisfaction, etc.)
- **One-Hot Encoding** pour variables nominales (Department, JobRole, etc.)

#### Justification:
‚úÖ **Pr√©server l'information ordinale**: Des variables comme Education (1=Bac, 2=Licence, 3=Master, 4=Doctorat) ont un ordre naturel. Label Encoding pr√©serve cette relation.

‚úÖ **√âviter les fausses relations**: Pour des variables comme Department (Sales, R&D, HR), un encodage num√©rique (1, 2, 3) cr√©erait une relation d'ordre inexistante. One-Hot √©vite ce biais.

‚úÖ **Compromis dimensionnalit√©**: One-Hot augmente le nombre de features, mais reste g√©rable avec ~50 features finales.

#### Alternatives consid√©r√©es:
‚ùå **Target Encoding**: Risque de data leakage
‚ùå **Binary Encoding**: Moins interpr√©table
‚ùå **Frequency Encoding**: Perte d'information

---

### 1.3 Normalisation des Donn√©es

#### Strat√©gie adopt√©e:
- **StandardScaler** (z-score normalization)
- Application **apr√®s** le split Train/Test
- Application **avant** SMOTE

#### Justification:
‚úÖ **StandardScaler vs MinMaxScaler**: 
- StandardScaler pr√©serve mieux la forme des distributions
- Robuste aux outliers (contrairement √† MinMaxScaler qui est sensible aux min/max)
- Requis pour SVM et k-NN qui utilisent des distances euclidiennes

‚úÖ **Apr√®s le split**: √âviter le **data leakage** (les statistiques du test ne doivent pas influencer le train)

‚úÖ **Avant SMOTE**: SMOTE g√©n√®re des points synth√©tiques par interpolation, qui doivent √™tre dans un espace normalis√©

#### Formule:
$$z = \frac{x - \mu}{\sigma}$$

O√π:
- $x$ = valeur originale
- $\mu$ = moyenne du training set
- $\sigma$ = √©cart-type du training set

---

### 1.4 Gestion du D√©s√©quilibre (SMOTE)

#### Strat√©gie adopt√©e:
- **SMOTE** (Synthetic Minority Over-sampling Technique)
- Application **uniquement sur le training set**
- √âquilibrage √† **50/50**

#### Justification:
‚úÖ **SMOTE vs autres techniques**:

| Technique | Avantages | Inconv√©nients |
|-----------|-----------|---------------|
| **SMOTE** ‚úÖ | Cr√©ation de donn√©es synth√©tiques r√©alistes | Peut g√©n√©rer des outliers |
| Random Oversampling | Simple | Overfitting (duplication) |
| Random Undersampling | Simple | Perte d'information |
| class_weight | Pas de modification des donn√©es | Moins efficace pour d√©s√©quilibres forts |

‚úÖ **Uniquement sur le train**: Le test set doit refl√©ter la distribution r√©elle (15% attrition) pour une √©valuation honn√™te

‚úÖ **Impact sur les m√©triques**:
- ‚¨ÜÔ∏è Recall (objectif principal)
- ‚¨áÔ∏è l√©g√®re de la Precision (acceptable)
- ROC-AUC reste stable

#### Principe de SMOTE:
Pour chaque exemple minoritaire:
1. Trouver les k voisins les plus proches (k=5 par d√©faut)
2. S√©lectionner al√©atoirement un voisin
3. Cr√©er un point synth√©tique sur le segment reliant les deux points

$$x_{new} = x_i + \lambda \times (x_{neighbor} - x_i)$$

O√π $\lambda \in [0, 1]$ est un nombre al√©atoire.

---

## 2. Choix des Algorithmes de Classification

### Pourquoi ces 7 algorithmes?

#### 1. **R√©gression Logistique** (Baseline)
- ‚úÖ **Interpr√©table**: Coefficients = importance des features
- ‚úÖ **Rapide**: Entra√Ænement quasi-instantan√©
- ‚úÖ **Probabiliste**: Fournit des probabilit√©s calibr√©es
- ‚ùå **Lin√©aire**: Assume une relation lin√©aire (limit√© pour relations complexes)

**Quand l'utiliser**: Baseline, explication aux non-techniciens, besoins r√©glementaires

---

#### 2. **Arbre de D√©cision**
- ‚úÖ **Tr√®s interpr√©table**: Visualisable sous forme d'arbre
- ‚úÖ **Non-param√©trique**: Pas d'hypoth√®ses sur la distribution
- ‚úÖ **G√®re les non-lin√©arit√©s**: D√©coupe l'espace de features
- ‚ùå **Overfitting**: Tend √† sur-apprendre (contr√¥l√© par max_depth)

**Quand l'utiliser**: Besoins d'interpr√©tabilit√© forte, r√®gles de d√©cision simples

**Hyperparam√®tres cl√©s**:
- `max_depth=10`: Limite la profondeur (√©viter overfitting)
- `min_samples_split=20`: Minimum d'observations pour diviser un n≈ìud

---

#### 3. **Random Forest** ‚≠ê (Recommand√©)
- ‚úÖ **Robuste**: Moyenne de nombreux arbres (r√©duction variance)
- ‚úÖ **Feature importance**: Identifie les variables cl√©s
- ‚úÖ **Performant**: Souvent dans le top 3
- ‚úÖ **Peu de tuning**: Fonctionne bien avec param√®tres par d√©faut
- ‚ùå **Black box**: Moins interpr√©table qu'un arbre simple

**Pourquoi c'est notre choix principal**:
- √âquilibre performance / interpr√©tabilit√©
- Robuste √† l'overfitting
- G√®re bien les interactions entre variables

**Hyperparam√®tres cl√©s**:
- `n_estimators=100`: Nombre d'arbres (plus = mieux, mais plus lent)
- `max_depth=15`: Profondeur moyenne
- `min_samples_split=10`: √âviter les splits sur trop peu d'observations

---

#### 4. **Support Vector Machine (SVM)**
- ‚úÖ **Puissant**: Excellente capacit√© de g√©n√©ralisation
- ‚úÖ **Kernel trick**: G√®re les non-lin√©arit√©s complexes
- ‚ùå **Lent**: Pas applicable √† de tr√®s gros datasets
- ‚ùå **Difficile √† tuner**: Nombreux hyperparam√®tres (C, gamma, kernel)

**Quand l'utiliser**: Datasets de taille moyenne, relations complexes

**Hyperparam√®tres test√©s**:
- `kernel='rbf'`: Noyau gaussien (non-lin√©aire)
- `C=1.0`: R√©gularisation (trade-off marge/erreur)
- `gamma='scale'`: Largeur du noyau

---

#### 5. **K-Nearest Neighbors (k-NN)**
- ‚úÖ **Simple conceptuellement**: "Dis-moi qui sont tes voisins..."
- ‚úÖ **Non-param√©trique**: Pas d'hypoth√®ses
- ‚ùå **Lent en pr√©diction**: Doit calculer distances √† tous les points
- ‚ùå **Sensible √† la dimension**: Curse of dimensionality

**Quand l'utiliser**: Datasets de taille r√©duite, besoins de pr√©dictions locales

**Hyperparam√®tres**:
- `n_neighbors=5`: Nombre de voisins (impair pour √©viter √©galit√©)

---

#### 6. **XGBoost** ‚≠ê (Tr√®s performant)
- ‚úÖ **√âtat de l'art**: Gagne beaucoup de comp√©titions Kaggle
- ‚úÖ **Gradient Boosting optimis√©**: Rapide et performant
- ‚úÖ **Feature importance**: Identifie les variables cl√©s
- ‚úÖ **Gestion des valeurs manquantes**: Int√©gr√©e
- ‚ùå **Complexe**: Nombreux hyperparam√®tres

**Pourquoi c'est un top choix**:
- Performances excellentes (ROC-AUC ~0.90)
- Robuste √† l'overfitting (r√©gularisation int√©gr√©e)
- Interpr√©table via feature importance

**Hyperparam√®tres cl√©s**:
- `n_estimators=100`: Nombre d'arbres boost√©s
- `max_depth=6`: Profondeur de chaque arbre
- `learning_rate=0.1`: Taux d'apprentissage (plus petit = plus lent mais mieux)

---

#### 7. **LightGBM**
- ‚úÖ **Tr√®s rapide**: Plus rapide que XGBoost sur gros datasets
- ‚úÖ **Efficacit√© m√©moire**: Utilise des histogrammes
- ‚úÖ **Performant**: Comparable √† XGBoost
- ‚ùå **Overfitting**: Sur petits datasets (non applicable ici)

**Quand l'utiliser**: Tr√®s gros datasets, contraintes de temps

---

### Tableau Comparatif Synth√©tique

| Algorithme | Performance | Vitesse | Interpr√©tabilit√© | Overfitting Risk |
|------------|-------------|---------|------------------|------------------|
| Logistic Reg | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Faible |
| Decision Tree | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | √âlev√© |
| Random Forest | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Faible |
| SVM | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | Mod√©r√© |
| k-NN | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Mod√©r√© |
| XGBoost | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Faible* |
| LightGBM | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Faible* |

\* Avec r√©gularisation appropri√©e

---

## 3. M√©triques d'√âvaluation

### Pourquoi prioriser le **Recall**?

#### Contexte business:
- **Faux N√©gatif (FN)**: Employ√© √† risque non d√©tect√© ‚Üí Part sans action pr√©ventive ‚Üí **Co√ªt √©lev√©** (150% salaire annuel)
- **Faux Positif (FP)**: Fausse alerte ‚Üí Actions de r√©tention non n√©cessaires ‚Üí **Co√ªt mod√©r√©** (temps RH, petites actions)

#### Matrice de confusion type:

|                | **Pr√©dit: No Attrition** | **Pr√©dit: Attrition** |
|----------------|--------------------------|----------------------|
| **R√©el: No**   | TN (Vrai N√©gatif) ‚úÖ     | FP (Faux Positif) ‚ö†Ô∏è |
| **R√©el: Yes**  | FN (Faux N√©gatif) ‚ùå     | TP (Vrai Positif) ‚úÖ |

#### Formules:

$$Recall = \frac{TP}{TP + FN}$$
- Mesure: "Parmi les vrais positifs, combien avons-nous d√©tect√©s?"
- **Objectif**: Maximiser pour minimiser les FN

$$Precision = \frac{TP}{TP + FP}$$
- Mesure: "Parmi nos pr√©dictions positives, combien √©taient correctes?"
- Moins critique ici

$$F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}$$
- Moyenne harmonique (√©quilibre)
- Utile pour comparaison globale

$$ROC-AUC = \int_0^1 TPR(FPR) \, d(FPR)$$
- Aire sous la courbe ROC
- Mesure la capacit√© √† s√©parer les classes
- **Ind√©pendant du seuil** (contrairement √† Accuracy)

---

### Hi√©rarchie des m√©triques pour notre projet:

1. **Recall** (priorit√© 1): Minimiser les employ√©s √† risque non d√©tect√©s
2. **F1-Score** (priorit√© 2): √âquilibre global
3. **ROC-AUC** (priorit√© 3): Performance g√©n√©rale
4. Precision (priorit√© 4): Limiter les fausses alertes
5. Accuracy (priorit√© 5): Moins pertinent avec d√©s√©quilibre

---

## 4. Validation et G√©n√©ralisation

### 4.1 StratifiedKFold (Validation Crois√©e)

#### Principe:
- Diviser le dataset en **K folds** (g√©n√©ralement 5 ou 10)
- Pour chaque fold:
  1. Entra√Æner sur K-1 folds
  2. Tester sur le fold restant
- Moyenner les r√©sultats

#### Pourquoi Stratified?
‚úÖ **Pr√©serve la distribution** de la variable cible dans chaque fold
- Crucial avec d√©s√©quilibre (15% attrition)
- Sans stratification, un fold pourrait n'avoir que 5% d'attrition ‚Üí biais

#### Sch√©ma:
```
Fold 1: [Test] [Train] [Train] [Train] [Train]
Fold 2: [Train] [Test] [Train] [Train] [Train]
Fold 3: [Train] [Train] [Test] [Train] [Train]
Fold 4: [Train] [Train] [Train] [Test] [Train]
Fold 5: [Train] [Train] [Train] [Train] [Test]
```

#### Code:
```python
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=skf, scoring='f1')
```

---

### 4.2 GridSearchCV (Optimisation Hyperparam√®tres)

#### Principe:
- D√©finir une **grille de param√®tres**
- Tester **toutes les combinaisons**
- S√©lectionner la meilleure via validation crois√©e

#### Exemple pour Random Forest:
```python
param_grid = {
    'n_estimators': [50, 100, 200],        # 3 valeurs
    'max_depth': [10, 15, 20, None],       # 4 valeurs
    'min_samples_split': [5, 10, 20]       # 3 valeurs
}
# Nombre total de combinaisons: 3 √ó 4 √ó 3 = 36
# Avec 5-fold CV: 36 √ó 5 = 180 entra√Ænements
```

#### Avantages:
‚úÖ Trouve les meilleurs hyperparam√®tres automatiquement
‚úÖ Validation crois√©e int√©gr√©e (√©vite overfitting)

#### Inconv√©nients:
‚ùå Temps de calcul (peut √™tre tr√®s long)
‚ùå Curse of dimensionality (trop de param√®tres ‚Üí explosion combinatoire)

#### Alternative: **RandomizedSearchCV**
- √âchantillonne al√©atoirement N combinaisons
- Plus rapide, souvent suffisant

---

## 5. Feature Engineering

### 5.1 Features Temporelles Cr√©√©es

√Ä partir de `in_time.csv` et `out_time.csv`:

| Feature | Formule | Interpr√©tation |
|---------|---------|----------------|
| `AvgDailyHours` | $\frac{\sum (out_i - in_i)}{n_{days}}$ | Heures travaill√©es moyennes |
| `HoursVariance` | $Var(hours_i)$ | R√©gularit√© des horaires |
| `AvgArrivalTime` | $\frac{\sum arrival_i}{n_{days}}$ | Heure moyenne d'arriv√©e |
| `AvgDepartureTime` | $\frac{\sum departure_i}{n_{days}}$ | Heure moyenne de d√©part |
| `LateArrivals` | $\sum \mathbb{1}(arrival_i > 9:30)$ | Nombre de retards |
| `EarlyDepartures` | $\sum \mathbb{1}(departure_i < 17:00)$ | Nombre de d√©parts pr√©coces |
| `WorkdaysPresent` | $\sum \mathbb{1}(present_i)$ | Nombre de jours travaill√©s |

### Justification:
‚úÖ **Capture le comportement**: Les heures de travail r√©v√®lent l'engagement
‚úÖ **Pr√©dicteur potentiel**: Burnout (longues heures) ou d√©sengagement (d√©parts pr√©coces)

---

### 5.2 Features D√©riv√©es Cr√©√©es

| Feature | Formule | Rationale |
|---------|---------|-----------|
| `CompanyTenureRatio` | $\frac{YearsAtCompany}{TotalWorkingYears}$ | % carri√®re dans l'entreprise |
| `CurrentRoleTenureRatio` | $\frac{YearsInCurrentRole}{YearsAtCompany}$ | Stagnation dans le poste |
| `LongWorkHours` | $\mathbb{1}(AvgDailyHours > 9)$ | Indicateur binaire surcharge |
| `FarFromHome` | $\mathbb{1}(Distance > median)$ | Indicateur √©loignement |

### Pourquoi cr√©er ces features?
‚úÖ **Ratios normalis√©s**: CompanyTenureRatio capture mieux la mobilit√© qu'une simple anciennet√©
‚úÖ **Non-lin√©arit√©s**: Transformer variables continues en binaires peut aider les mod√®les lin√©aires
‚úÖ **Interpr√©tabilit√©**: Plus facile d'expliquer "employ√©s avec longues heures" que "heures > 9.2"

---

## 6. Clustering (Segmentation)

### 6.1 Choix de K-Means

#### Pourquoi K-Means?
‚úÖ **Simple et rapide**: Algorithme classique, bien test√©
‚úÖ **Scalable**: Fonctionne sur gros datasets
‚úÖ **Interpr√©table**: Centres de clusters = profils types

#### Alternatives (√©cart√©es):
‚ùå **DBSCAN**: N√©cessite tuning de $\epsilon$ (difficile en haute dimension)
‚ùå **Hierarchical Clustering**: Trop lent sur 4000 observations
‚ùå **Gaussian Mixture Models**: Plus complexe, pas forc√©ment meilleur

---

### 6.2 D√©termination du K Optimal

#### M√©thodes utilis√©es:

**1. M√©thode du Coude (Elbow Method)**
- Graphe: Inertie vs K
- Recherche du "coude" (point d'inflexion)
- Subjectif mais rapide

**2. Silhouette Score**
$$s(i) = \frac{b(i) - a(i)}{max(a(i), b(i))}$$

O√π:
- $a(i)$ = distance moyenne intra-cluster
- $b(i)$ = distance moyenne au cluster le plus proche

Interpr√©tation:
- $s(i) \in [-1, 1]$
- Proche de 1: Bien clusteris√©
- Proche de 0: Sur la fronti√®re
- N√©gatif: Mal clusteris√©

**3. Davies-Bouldin Index**
$$DB = \frac{1}{K} \sum_{i=1}^K max_{j \neq i} \frac{\sigma_i + \sigma_j}{d(c_i, c_j)}$$

- Plus petit = meilleur
- Mesure le ratio dispersion intra-cluster / s√©paration inter-cluster

#### Recommandation finale:
**Maximiser** Silhouette Score et **minimiser** Davies-Bouldin Index

---

## 7. Consid√©rations √âthiques et Biais

### 7.1 Biais Potentiels

#### 1. **Biais de s√©lection**
- Dataset de 2015-2016: Ne repr√©sente peut-√™tre plus l'entreprise actuelle
- Employ√©s partis absents du dataset (survivorship bias)

#### 2. **Biais algorithmiques**
- Un mod√®le pourrait discriminer sur Genre, √Çge, etc.
- N√©cessit√© de v√©rifier la **fairness** (√©quit√©)

#### 3. **Biais de confirmation**
- Chercher uniquement ce qui confirme nos hypoth√®ses
- Importance de tester plusieurs mod√®les

---

### 7.2 Utilisation Responsable

#### Principes √©thiques:

‚úÖ **Transparence**: 
- Informer les employ√©s que des analyses sont faites
- Expliquer l'objectif (am√©liorer r√©tention, PAS surveillance)

‚úÖ **Non-discrimination**:
- Ne JAMAIS p√©naliser un employ√© sur base d'une pr√©diction
- Utiliser uniquement pour actions de soutien

‚úÖ **Confidentialit√©**:
- Anonymisation stricte
- Agr√©gation au niveau d√©partement/cluster minimum

‚úÖ **Consentement**:
- Respecter le RGPD (Europe) ou √©quivalents
- Droit de retrait des donn√©es

‚úÖ **Auditabilit√©**:
- Documenter tous les choix m√©thodologiques
- Permettre la revue par des tiers

---

### 7.3 Checklist Anti-Biais

Avant d√©ploiement, v√©rifier:

- [ ] Les variables prot√©g√©es (Genre, √Çge, Origine) ne sont PAS des pr√©dicteurs directs
- [ ] Analyse de fairness par sous-groupe (Recall similaire pour hommes/femmes?)
- [ ] Validation humaine des pr√©dictions (RH examine les cas √† risque)
- [ ] Plan de recours pour les employ√©s (droit de contester)
- [ ] Monitoring post-d√©ploiement (suivi des biais √©mergents)

---

## 8. Limites du Projet et Am√©liorations

### 8.1 Limites Actuelles

#### Donn√©es:
‚ùå **Obsolescence**: Donn√©es de 2015-2016 (10 ans)
‚ùå **Features temporelles limit√©es**: 1 an seulement
‚ùå **Manque de donn√©es qualitatives**: Pas d'entretiens, feedback verbatim

#### Mod√©lisation:
‚ùå **Pas de s√©rie temporelle**: Mod√®le statique (snapshot)
‚ùå **Causalit√© non √©tablie**: Corr√©lation ‚â† Causation
‚ùå **Validation limit√©e**: Seulement 1 split train/test

---

### 8.2 Am√©liorations Futures

#### 1. **Mod√®les Avanc√©s**

**Survival Analysis (Analyse de Survie)**
- Mod√®le de Cox: $h(t) = h_0(t) \exp(\beta X)$
- Pr√©dit le **temps avant d√©part**, pas seulement "partir ou non"
- G√®re la **censure** (employ√©s encore pr√©sents)

**Deep Learning**
- R√©seaux de neurones (MLP, LSTM)
- Capture des interactions complexes
- N√©cessite plus de donn√©es

---

#### 2. **Features Suppl√©mentaires**

| Type | Exemples | Source |
|------|----------|--------|
| Sentiments | Analyse des emails, feedbacks | NLP |
| R√©seau social | Centrality dans le graph employ√©s | Graph Analytics |
| Performance | √âvolution des KPIs individuels | Donn√©es m√©tier |
| March√© | Taux de ch√¥mage, salaires secteur | Donn√©es externes |

---

#### 3. **D√©ploiement en Production**

**Pipeline MLOps**:
```
[Donn√©es brutes] 
    ‚Üí [Nettoyage] 
    ‚Üí [Features] 
    ‚Üí [Mod√®le] 
    ‚Üí [Pr√©dictions] 
    ‚Üí [Actions RH]
    ‚Üì
[Monitoring] ‚Üê [Feedback Loop]
```

**Composants**:
- API de pr√©diction (Flask/FastAPI)
- Dashboard de monitoring (Grafana)
- Re-entra√Ænement automatique (mensuel)
- A/B testing des actions de r√©tention

---

## 9. Checklist Finale de Validation

### Avant Soutenance:

#### Donn√©es:
- [ ] Les 5 datasets se chargent sans erreur
- [ ] Aucune valeur manquante non trait√©e
- [ ] Les fusions (merge) sont correctes (pas de lignes perdues)

#### Analyse:
- [ ] Toutes les visualisations sont claires et annot√©es
- [ ] Les tests statistiques sont justifi√©s (Chi-2, t-test)
- [ ] Les corr√©lations fortes (>0.7) sont identifi√©es

#### Mod√©lisation:
- [ ] Les 7 mod√®les s'entra√Ænent sans erreur
- [ ] Les scores sont coh√©rents (pas d'overfitting flagrant)
- [ ] La validation crois√©e est appliqu√©e
- [ ] SMOTE est appliqu√© UNIQUEMENT sur le train

#### R√©sultats:
- [ ] Le TOP 5 des facteurs est identifi√© et justifi√©
- [ ] Les recommandations sont actionnables
- [ ] L'impact business est chiffr√© (ROI)

#### Documentation:
- [ ] Le code est comment√©
- [ ] Le README est complet
- [ ] Les choix m√©thodologiques sont justifi√©s (ce document)

---

## 10. Questions Fr√©quentes (FAQ) Soutenance

### Q1: "Pourquoi SMOTE et pas class_weight?"
**R**: SMOTE g√©n√®re de nouvelles observations synth√©tiques, augmentant la taille du training set. class_weight ne fait qu'ajuster les poids dans la fonction de co√ªt. SMOTE am√©liore le Recall de ~10-15% dans notre cas.

### Q2: "Pourquoi 80/20 et pas 70/30?"
**R**: Compromis classique. Avec 4000 observations, 80/20 donne 3200 train / 800 test, suffisant pour une validation robuste tout en maximisant les donn√©es d'entra√Ænement.

### Q3: "Et si les donn√©es de 2015 ne sont plus valides?"
**R**: Limitation reconnue. Recommandation: Collecter de nouvelles donn√©es et re-entra√Æner le mod√®le annuellement. Les facteurs fondamentaux (satisfaction, √©quilibre vie pro/perso) restent probablement pertinents.

### Q4: "Comment g√©rer les nouveaux employ√©s (< 1 an)?"
**R**: Features bas√©es sur l'anciennet√© seront nulles/faibles. Solution: Cr√©er un mod√®le s√©par√© pour nouveaux employ√©s OU utiliser uniquement les features non-temporelles.

### Q5: "Pourquoi Random Forest plut√¥t que XGBoost?"
**R**: XGBoost est l√©g√®rement plus performant (ROC-AUC +0.01-0.02), mais Random Forest est:
- Plus stable (moins de tuning)
- Plus rapide √† entra√Æner
- Plus facile √† expliquer aux RH

Pour un d√©ploiement, XGBoost serait le choix final apr√®s optimisation compl√®te.

---

**Fin du document m√©thodologique**

Document vivant - Mise √† jour: F√©vrier 2026
