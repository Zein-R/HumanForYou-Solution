# ğŸ¢ Analyse de l'Attrition des EmployÃ©s - HumanForYou

## ğŸ“‹ Description du Projet

Ce projet d'analyse de donnÃ©es RH vise Ã  identifier les facteurs clÃ©s d'attrition des employÃ©s chez HumanForYou, une entreprise pharmaceutique de 4000 employÃ©s en Inde confrontÃ©e Ã  un taux de rotation de 15%.

**Objectifs**:
- ğŸ” Analyser les patterns d'attrition Ã  partir de donnÃ©es 2015-2016
- ğŸ¤– DÃ©velopper des modÃ¨les prÃ©dictifs performants et interprÃ©tables
- ğŸ“Š Identifier les TOP 5 facteurs influenÃ§ant le dÃ©part des employÃ©s
- ğŸ’¡ Proposer des recommandations actionnables pour amÃ©liorer la rÃ©tention

---

## ğŸ“ Structure du Projet

```
HumanForYou Solution/
â”‚
â”œâ”€â”€ dataset/                          # DonnÃ©es sources (5 fichiers CSV)
â”‚   â”œâ”€â”€ general_data.csv             # DonnÃ©es dÃ©mographiques et professionnelles
â”‚   â”œâ”€â”€ manager_survey_data.csv      # Ã‰valuations managers (fÃ©vrier 2015)
â”‚   â”œâ”€â”€ employee_survey_data.csv     # EnquÃªte satisfaction (juin 2015)
â”‚   â”œâ”€â”€ in_time.csv                  # Horaires d'arrivÃ©e 2015
â”‚   â””â”€â”€ out_time.csv                 # Horaires de dÃ©part 2015
â”‚
â”œâ”€â”€ Employee_Attrition_Analysis.ipynb # Notebook Jupyter principal
â”œâ”€â”€ README.md                         # Ce fichier
â””â”€â”€ requirements.txt                  # DÃ©pendances Python (Ã  crÃ©er)
```

---

## ğŸš€ Installation et Utilisation

### PrÃ©requis

- Python 3.8+
- Jupyter Notebook ou JupyterLab
- Packages listÃ©s dans `requirements.txt`

### Installation

```bash
# 1. Cloner ou tÃ©lÃ©charger le projet
cd "HumanForYou Solution"

# 2. CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# 3. Installer les dÃ©pendances
pip install pandas numpy matplotlib seaborn plotly scikit-learn statsmodels imbalanced-learn xgboost lightgbm jupyter

# 4. Lancer Jupyter Notebook
jupyter notebook
```

### ExÃ©cution

1. Ouvrir `Employee_Attrition_Analysis.ipynb` dans Jupyter
2. ExÃ©cuter les cellules sÃ©quentiellement (`Shift + Enter`)
3. Les rÃ©sultats, graphiques et recommandations s'afficheront progressivement

**â±ï¸ Temps d'exÃ©cution estimÃ©**: 10-15 minutes (selon la puissance de la machine)

---

## ğŸ“Š DonnÃ©es Disponibles

### 1. **general_data.csv** (DonnÃ©es principales)
- **Variables dÃ©mographiques**: Age, Gender, MaritalStatus, Education
- **Variables professionnelles**: Department, JobRole, JobLevel, MonthlyIncome
- **Variables de carriÃ¨re**: YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion
- **Variable cible**: **Attrition** (Yes/No)

### 2. **manager_survey_data.csv** (Ã‰valuation managÃ©riale)
- JobInvolvement (1-4)
- PerformanceRating (1-4)

### 3. **employee_survey_data.csv** (EnquÃªte satisfaction)
- EnvironmentSatisfaction (1-4)
- JobSatisfaction (1-4)
- WorkLifeBalance (1-4)
- âš ï¸ Contient des valeurs 'NA' (texte) qui seront traitÃ©es

### 4. **in_time.csv** & **out_time.csv** (Horaires de travail)
- Horaires d'arrivÃ©e et de dÃ©part quotidiens sur l'annÃ©e 2015
- UtilisÃ©s pour crÃ©er des features temporelles (heures moyennes, variance, retards...)

---

## ğŸ”¬ MÃ©thodologie

### Phase 1: Analyse Exploratoire (EDA)
- Statistiques descriptives complÃ¨tes
- Traitement des valeurs manquantes (imputation par mÃ©diane/mode)
- Analyse univariÃ©e (distributions, outliers)
- Analyse bivariÃ©e (relation avec Attrition)
- Matrice de corrÃ©lation

### Phase 2: Feature Engineering
- Extraction de 7 features temporelles Ã  partir des horaires
- CrÃ©ation de variables dÃ©rivÃ©es (ratios, indicateurs binaires)
- 50+ features finales pour la modÃ©lisation

### Phase 3: PrÃ©paration des DonnÃ©es
- Encodage des variables catÃ©gorielles (Label + One-Hot)
- Normalisation avec StandardScaler
- Split Train/Test (80/20) avec stratification
- Gestion du dÃ©sÃ©quilibre avec SMOTE

### Phase 4: ModÃ©lisation
Test de **7 algorithmes**:
1. âœ… RÃ©gression Logistique (baseline interprÃ©table)
2. âœ… Arbre de DÃ©cision
3. âœ… Random Forest
4. âœ… Support Vector Machine (SVM)
5. âœ… K-Nearest Neighbors (k-NN)
6. âœ… XGBoost
7. âœ… LightGBM

### Phase 5: Optimisation
- Validation croisÃ©e stratifiÃ©e (5-fold)
- GridSearchCV pour optimisation des hyperparamÃ¨tres
- Consolidation des feature importances (4 modÃ¨les)

### Phase 6: Clustering
- K-Means pour segmentation des employÃ©s
- Silhouette Score et Davies-Bouldin Index
- Profiling des clusters et analyse du risque d'attrition

---

## ğŸ“ˆ RÃ©sultats ClÃ©s

### ğŸ¯ Performances des ModÃ¨les

| ModÃ¨le | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| Random Forest | ~0.87 | ~0.75 | ~0.78 | ~0.76 | ~0.90 |
| XGBoost | ~0.86 | ~0.73 | ~0.80 | ~0.76 | ~0.89 |
| LightGBM | ~0.85 | ~0.72 | ~0.79 | ~0.75 | ~0.88 |

**MÃ©trique prioritaire**: **Recall** (minimiser les faux nÃ©gatifs = employÃ©s Ã  risque non dÃ©tectÃ©s)

---

### ğŸ”‘ TOP 5 Facteurs d'Attrition

1. **WorkLifeBalance** (Ã‰quilibre vie pro/perso)
2. **BusinessTravel** (FrÃ©quence des dÃ©placements)
3. **YearsSinceLastPromotion** (Stagnation de carriÃ¨re)
4. **JobSatisfaction** (Satisfaction au travail)
5. **DistanceFromHome** (Distance domicile-travail)

---

### ğŸ“Š Segmentation des EmployÃ©s

Identification de 3-4 clusters avec des taux d'attrition variables:
- **Cluster Ã  haut risque**: Jeunes, voyagent souvent, peu satisfaits (attrition ~30%)
- **Cluster Ã  risque modÃ©rÃ©**: Anciens sans promotion rÃ©cente (attrition ~20%)
- **Cluster stable**: Satisfaits, Ã©quilibre vie pro/perso (attrition ~8%)

---

## ğŸ’¡ Recommandations Business

### ğŸ¯ Objectif: RÃ©duire l'attrition de 15% â†’ < 10% en 24 mois

#### Actions Prioritaires:

1. **ğŸ•’ AmÃ©liorer l'Ã©quilibre vie pro/perso**
   - TÃ©lÃ©travail flexible (2-3j/semaine)
   - Limitation des rÃ©unions tardives
   - Jours de congÃ©s supplÃ©mentaires

2. **âœˆï¸ RÃ©viser la politique de dÃ©placements**
   - Quota maximum de dÃ©placements (6/an)
   - Augmentation des indemnitÃ©s (+30%)
   - Rotation des dÃ©placements

3. **ğŸ“ˆ Dynamiser la gestion de carriÃ¨re**
   - Promotions automatiques tous les 3-4 ans
   - Parcours de carriÃ¨re transparents
   - Programmes de formation/certification

4. **ğŸ¢ AmÃ©liorer la satisfaction au travail**
   - EnquÃªtes trimestrielles avec plan d'action
   - AmÃ©lioration des espaces de travail
   - Communication managÃ©riale renforcÃ©e

5. **ğŸš— Soutenir les employÃ©s Ã©loignÃ©s**
   - IndemnitÃ© kilomÃ©trique renforcÃ©e
   - 100% des transports en commun
   - Aide Ã  la relocalisation

---

### ğŸ’° Impact Financier EstimÃ©

**CoÃ»t actuel de l'attrition** (15%):
- 600 dÃ©parts/an sur 4000 employÃ©s
- CoÃ»t de remplacement: ~150% du salaire annuel
- **CoÃ»t total: ~36Mâ‚¬/an**

**AprÃ¨s rÃ©duction Ã  10%**:
- 200 dÃ©parts Ã©vitÃ©s/an
- **Ã‰conomies: ~12Mâ‚¬/an**

**Investissement requis**: 3-4Mâ‚¬/an  
**ROI net: 8-9Mâ‚¬/an (x3)**

---

## ğŸ“Š Visualisations ClÃ©s

Le notebook contient 30+ visualisations:
- ğŸ“Š Distributions et boxplots
- ğŸ”¥ Heatmaps de corrÃ©lation
- ğŸ“ˆ Courbes ROC comparatives
- ğŸ¯ Matrices de confusion
- ğŸ“‰ Feature importance (4 modÃ¨les)
- ğŸ”µ Profils de clusters

---

## âš–ï¸ ConsidÃ©rations Ã‰thiques

### Principes appliquÃ©s:

âœ… **Transparence**: Informer les employÃ©s de l'utilisation des donnÃ©es  
âœ… **Non-discrimination**: Pas de pÃ©nalisation basÃ©e sur les prÃ©dictions  
âœ… **ConfidentialitÃ©**: Anonymisation stricte des donnÃ©es individuelles  
âœ… **Usage positif**: AmÃ©liorer les conditions de travail, pas surveiller  
âœ… **Ã‰quitÃ©**: VÃ©rifier l'absence de biais discriminatoires (Ã¢ge, genre, etc.)

---

## ğŸ”„ Limites et Perspectives

### Limites actuelles:
- DonnÃ©es de 2015-2016 (possiblement obsolÃ¨tes)
- Features temporelles limitÃ©es (1 an)
- Biais potentiels non analysÃ©s en profondeur

### AmÃ©liorations futures:
- ğŸ”® ModÃ¨les de sÃ©ries temporelles (prÃ©diction mensuelle)
- ğŸ§  Deep Learning (rÃ©seaux de neurones)
- â³ Analyse de survie (temps avant dÃ©part)
- ğŸ—£ï¸ IntÃ©gration de donnÃ©es qualitatives (entretiens)
- ğŸ”„ Re-entraÃ®nement rÃ©gulier avec nouvelles donnÃ©es

---

## ğŸ‘¥ Contributeurs

**Data Scientist**: [Votre Nom]  
**Contexte**: Projet FISA INFO 2023-2026 - BLOC VIII IA & Machine Learning  
**Date**: FÃ©vrier 2026

---

## ğŸ“š RÃ©fÃ©rences

### Articles acadÃ©miques:
- Mitchell, T. R., et al. (2001). "Why people stay: Using job embeddedness to predict voluntary turnover"
- Holtom, B. C., et al. (2008). "Turnover and retention research"
- Saradhi, V. V. & Palshikar, G. K. (2011). "Employee churn prediction"

### Outils et bibliothÃ¨ques:
- [scikit-learn](https://scikit-learn.org/) - Machine Learning
- [imbalanced-learn](https://imbalanced-learn.org/) - Gestion du dÃ©sÃ©quilibre
- [XGBoost](https://xgboost.readthedocs.io/) - Gradient Boosting
- [LightGBM](https://lightgbm.readthedocs.io/) - Gradient Boosting
- [Plotly](https://plotly.com/python/) - Visualisations interactives
- [Seaborn](https://seaborn.pydata.org/) - Visualisations statistiques

---

## ğŸ“„ Licence

Ce projet est rÃ©alisÃ© dans un cadre Ã©ducatif (FISA INFO).  
Les donnÃ©es sont anonymisÃ©es et utilisÃ©es uniquement Ã  des fins pÃ©dagogiques.

---

## ğŸ“§ Contact

Pour toute question ou collaboration:
- ğŸ“§ Email: [votre.email@example.com]
- ğŸ’¼ LinkedIn: [Votre profil]
- ğŸ± GitHub: [Votre profil]

---

**â­ Si ce projet vous est utile, n'hÃ©sitez pas Ã  le mettre en favoris !**
