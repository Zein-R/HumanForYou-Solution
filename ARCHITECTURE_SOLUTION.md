# üèóÔ∏è Architecture de la Solution - HumanForYou Attrition Analysis

## üìÅ Structure du Projet

```
HumanForYou Solution/
‚îÇ
‚îú‚îÄ‚îÄ üìä dataset/                                    # Donn√©es sources
‚îÇ   ‚îú‚îÄ‚îÄ general_data.csv                          # Donn√©es d√©mographiques
‚îÇ   ‚îú‚îÄ‚îÄ manager_survey_data.csv                   # √âvaluations managers
‚îÇ   ‚îú‚îÄ‚îÄ employee_survey_data.csv                  # Enqu√™te satisfaction
‚îÇ   ‚îú‚îÄ‚îÄ in_time.csv                               # Horaires d'arriv√©e
‚îÇ   ‚îî‚îÄ‚îÄ out_time.csv                              # Horaires de d√©part
‚îÇ
‚îú‚îÄ‚îÄ üìì Employee_Attrition_Analysis.ipynb          # ‚≠ê Notebook principal
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Section 1: Configuration                  # Setup et imports
‚îÇ   ‚îú‚îÄ‚îÄ Section 2: Chargement                     # Fusion des 5 datasets
‚îÇ   ‚îú‚îÄ‚îÄ Section 3: EDA                            # Analyse exploratoire
‚îÇ   ‚îú‚îÄ‚îÄ Section 4: Feature Engineering            # Cr√©ation df_enriched
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Section 5: Pr√©paration (Split Tardif)     # ‚ùå Avec data leakage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5.1: Imputation (TOUT le dataset)    # üö® LEAKAGE ICI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5.2: Encodage (TOUT le dataset)      # üö® LEAKAGE ICI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5.3: Split train/test                # Trop tard !
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5.4: Standardisation                  # ‚úÖ OK
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 5.5: SMOTE                            # ‚úÖ OK
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Section 5bis: Pr√©paration (Split Pr√©coce) # ‚úÖ Best Practice - NOUVEAU
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5bis.1: Split IMM√âDIAT               # ‚úÖ AVANT transformations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5bis.2: Imputation (fit/transform)   # ‚úÖ Pas de leakage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5bis.3: Encodage (fit/transform)     # ‚úÖ Pas de leakage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5bis.4: Standardisation              # ‚úÖ Pas de leakage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5bis.5: SMOTE (train uniquement)     # ‚úÖ Pas de leakage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5bis.6: R√©capitulatif                # üìã R√©sum√©
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 5bis.7: Mod√©lisation (6 mod√®les)     # ü§ñ Entra√Ænement
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Section 5ter: Comparaison                 # üìä Analyse comparative - NOUVEAU
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5ter.1: Pr√©paration donn√©es          # R√©cup√©ration r√©sultats
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5ter.2: Tableau comparatif           # Calcul diff√©rences
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5ter.3: Visualisations               # Graphiques barres + heatmap
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5ter.4: Analyse approfondie          # Stats et interpr√©tation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 5ter.5: Recommandations              # Conclusion m√©thodologique
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Section 6: Mod√©lisation (Split Tardif)    # ‚ùå Avec leakage potentiel
‚îÇ   ‚îú‚îÄ‚îÄ Section 7: Optimisation                   # Hyperparam√®tres
‚îÇ   ‚îú‚îÄ‚îÄ Section 8: Clustering                     # Segmentation
‚îÇ   ‚îú‚îÄ‚îÄ Section 9: Recommandations Business       # Actions concr√®tes
‚îÇ   ‚îî‚îÄ‚îÄ Section 10: Conclusion                    # Synth√®se finale
‚îÇ
‚îú‚îÄ‚îÄ üìö Documentation/
‚îÇ   ‚îú‚îÄ‚îÄ README.md                                 # Vue d'ensemble du projet
‚îÇ   ‚îú‚îÄ‚îÄ METHODOLOGIE.md                           # Justifications scientifiques
‚îÇ   ‚îú‚îÄ‚îÄ QUICK_START.md                            # Guide de d√©marrage rapide
‚îÇ   ‚îú‚îÄ‚îÄ GUIDE_SECTION_5BIS.md                     # üìò Guide d'utilisation 5bis - NOUVEAU
‚îÇ   ‚îî‚îÄ‚îÄ RECAPITULATIF_MODIFICATIONS.md            # üìù Changelog technique - NOUVEAU
‚îÇ
‚îú‚îÄ‚îÄ üîß Scripts de correction/
‚îÇ   ‚îú‚îÄ‚îÄ SOLUTION_CELLULE_30.py                    # Fix Plotly rendering
‚îÇ   ‚îî‚îÄ‚îÄ FONCTION_CORRIGEE_extract_time_features.py # Fix EmployeeID KeyError
‚îÇ
‚îú‚îÄ‚îÄ üì¶ Configuration/
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                          # D√©pendances Python
‚îÇ   ‚îî‚îÄ‚îÄ .gitignore                                # Fichiers √† exclure
‚îÇ
‚îî‚îÄ‚îÄ üöÄ OPTIMISATION_CELLULE_44.py                 # Optimisation feature extraction

```

---

## üîÑ Flux de Donn√©es - Comparaison des Approches

### Approche 1: Split Tardif (Section 5) - ‚ùå Avec Data Leakage

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  √âTAPE 1: CHARGEMENT ET FUSION                                               ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  general_data.csv (4410 lignes)                                              ‚îÇ
‚îÇ  manager_survey.csv (4410 lignes)        ‚îÄ‚îÄ‚îÄ‚ñ∫ [MERGE]  ‚îÄ‚îÄ‚îÄ‚ñ∫  df_merged     ‚îÇ
‚îÇ  employee_survey.csv (4410 lignes)                          (4410 lignes)    ‚îÇ
‚îÇ  time_features (4000 lignes)                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  √âTAPE 2: FEATURE ENGINEERING                                                ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  df_merged  ‚îÄ‚îÄ‚îÄ‚ñ∫ [Calculs]  ‚îÄ‚îÄ‚îÄ‚ñ∫  df_enriched                              ‚îÇ
‚îÇ                                    (4410 lignes, ~40 features)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚ö†Ô∏è √âTAPE 3: IMPUTATION (SUR TOUT LE DATASET) - üö® DATA LEAKAGE             ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  df_enriched  ‚îÄ‚îÄ‚îÄ‚ñ∫  [Calcul m√©diane/mode sur 4410 lignes]  ‚îÄ‚îÄ‚îÄ‚ñ∫  df_clean ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  Probl√®me: La m√©diane des 4410 lignes inclut les donn√©es du futur test set! ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚ö†Ô∏è √âTAPE 4: ENCODAGE (SUR TOUT LE DATASET) - üö® DATA LEAKAGE               ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  df_clean  ‚îÄ‚îÄ‚îÄ‚ñ∫  [LabelEncoder.fit() sur 4410 lignes]  ‚îÄ‚îÄ‚îÄ‚ñ∫  df_encoded   ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  Probl√®me: L'encodeur est ajust√© sur toutes les cat√©gories (train + test)!  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  √âTAPE 5: SPLIT TRAIN/TEST (TROP TARD!)                                     ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  df_encoded  ‚îÄ‚îÄ‚îÄ‚ñ∫  [train_test_split]  ‚îÄ‚îÄ‚îÄ‚ñ∫  X_train (3528 lignes, 80%)    ‚îÇ
‚îÇ                                           ‚îî‚îÄ‚îÄ‚ñ∫  X_test  (882 lignes, 20%)    ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  X_train et X_test ont d√©j√† "vu" les statistiques l'un de l'autre!          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  √âTAPE 6-7: STANDARDISATION + SMOTE (CORRECT)                               ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  X_train  ‚îÄ‚îÄ‚îÄ‚ñ∫  [scaler.fit(train)]      ‚îÄ‚îÄ‚îÄ‚ñ∫  X_train_scaled              ‚îÇ
‚îÇ  X_test   ‚îÄ‚îÄ‚îÄ‚ñ∫  [scaler.transform(test)] ‚îÄ‚îÄ‚îÄ‚ñ∫  X_test_scaled               ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  X_train_scaled  ‚îÄ‚îÄ‚îÄ‚ñ∫  [SMOTE]  ‚îÄ‚îÄ‚îÄ‚ñ∫  X_train_smote (~6000 lignes)         ‚îÇ
‚îÇ  X_test_scaled reste inchang√©                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  √âTAPE 8: MOD√âLISATION (avec donn√©es contamin√©es)                           ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  X_train_smote  ‚îÄ‚îÄ‚îÄ‚ñ∫  [Mod√®le.fit()]  ‚îÄ‚îÄ‚îÄ‚ñ∫  Mod√®le entra√Æn√©                ‚îÇ
‚îÇ  X_test_scaled  ‚îÄ‚îÄ‚îÄ‚ñ∫  [Mod√®le.predict()]  ‚îÄ‚îÄ‚îÄ‚ñ∫  Performances SURESTIM√âES   ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚ùå R√©sultat: F1-Score artificiellement gonfl√© de 1-5%                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Approche 2: Split Pr√©coce (Section 5bis) - ‚úÖ Best Practice

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  √âTAPE 1-2: CHARGEMENT ET FEATURE ENGINEERING (identique)                   ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  5 datasets  ‚îÄ‚îÄ‚îÄ‚ñ∫  [MERGE + Feature Engineering]  ‚îÄ‚îÄ‚îÄ‚ñ∫  df_enriched        ‚îÇ
‚îÇ                                                          (4410 lignes)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚úÖ √âTAPE 3: SPLIT IMM√âDIAT (AVANT TOUTE TRANSFORMATION)                    ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  df_enriched  ‚îÄ‚îÄ‚îÄ‚ñ∫  [train_test_split]  ‚îÄ‚îÄ‚îÄ‚ñ∫  X_train (3528 lignes, 80%)   ‚îÇ
‚îÇ                                           ‚îî‚îÄ‚îÄ‚ñ∫  X_test  (882 lignes, 20%)    ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚úÖ Aucune information du test ne peut "fuiter" vers le train maintenant!   ‚îÇ
‚îÇ  ‚úÖ Les deux sets sont compl√®tement ind√©pendants                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚úÖ √âTAPE 4: IMPUTATION (FIT sur train, TRANSFORM sur test)                 ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  X_train (3528)  ‚îÄ‚îÄ‚îÄ‚ñ∫  [imputer.fit()]       ‚îÄ‚îÄ‚îÄ‚ñ∫  Calcul m√©diane/mode     ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚ñ∫  [imputer.transform()] ‚îÄ‚îÄ‚îÄ‚ñ∫  X_train_clean          ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  X_test (882)    ‚îÄ‚îÄ‚îÄ‚ñ∫  [imputer.transform()]  ‚îÄ‚îÄ‚îÄ‚ñ∫  X_test_clean           ‚îÇ
‚îÇ                        (utilise m√©diane du train)                            ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚úÖ Le test set n'influence PAS les statistiques d'imputation                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚úÖ √âTAPE 5: ENCODAGE (FIT sur train, TRANSFORM sur test)                   ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  X_train_clean  ‚îÄ‚îÄ‚îÄ‚ñ∫  [encoder.fit()]       ‚îÄ‚îÄ‚îÄ‚ñ∫  Apprend cat√©gories train ‚îÇ
‚îÇ                  ‚îî‚îÄ‚îÄ‚ñ∫  [encoder.transform()] ‚îÄ‚îÄ‚îÄ‚ñ∫  X_train_encoded         ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  X_test_clean   ‚îÄ‚îÄ‚îÄ‚ñ∫  [encoder.transform()]  ‚îÄ‚îÄ‚îÄ‚ñ∫  X_test_encoded          ‚îÇ
‚îÇ                       (utilise cat√©gories du train)                          ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚úÖ Le test set n'influence PAS les cat√©gories de l'encodeur                ‚îÇ
‚îÇ  ‚úÖ Gestion des cat√©gories inconnues (si test contient des nouvelles)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚úÖ √âTAPE 6-7: STANDARDISATION + SMOTE (FIT sur train)                      ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  X_train_encoded  ‚îÄ‚îÄ‚îÄ‚ñ∫  [scaler.fit()]       ‚îÄ‚îÄ‚îÄ‚ñ∫  Calcul mean/std train   ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚ñ∫  [scaler.transform()] ‚îÄ‚îÄ‚îÄ‚ñ∫  X_train_scaled         ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  X_test_encoded   ‚îÄ‚îÄ‚îÄ‚ñ∫  [scaler.transform()]  ‚îÄ‚îÄ‚îÄ‚ñ∫  X_test_scaled          ‚îÇ
‚îÇ                         (utilise mean/std du train)                          ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  X_train_scaled   ‚îÄ‚îÄ‚îÄ‚ñ∫  [SMOTE.fit_resample()] ‚îÄ‚îÄ‚îÄ‚ñ∫  X_train_smote         ‚îÇ
‚îÇ  X_test_scaled reste inchang√© (distribution naturelle)                       ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚úÖ Toutes les transformations bas√©es UNIQUEMENT sur le train               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚úÖ √âTAPE 8: MOD√âLISATION (avec donn√©es propres)                            ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  X_train_smote  ‚îÄ‚îÄ‚îÄ‚ñ∫  [Mod√®le.fit()]  ‚îÄ‚îÄ‚îÄ‚ñ∫  Mod√®le entra√Æn√©                ‚îÇ
‚îÇ  X_test_scaled  ‚îÄ‚îÄ‚îÄ‚ñ∫  [Mod√®le.predict()]  ‚îÄ‚îÄ‚îÄ‚ñ∫  Performances R√âALISTES     ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚úÖ R√©sultat: F1-Score refl√®te la vraie performance en production           ‚îÇ
‚îÇ  ‚úÖ Pas de surestimation, estimation honn√™te                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Comparaison des Performances (Section 5ter)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                               ‚îÇ
‚îÇ  Section 5 (Split Tardif)          Section 5bis (Split Pr√©coce)             ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ          ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ            ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó          ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó               ‚îÇ
‚îÇ  ‚ïë  Logistic Regression  ‚ïë          ‚ïë  Logistic Regression  ‚ïë               ‚îÇ
‚îÇ  ‚ïë  F1: 0.675            ‚ïë          ‚ïë  F1: 0.652            ‚ïë               ‚îÇ
‚îÇ  ‚ïë  ROC-AUC: 0.853       ‚ïë          ‚ïë  ROC-AUC: 0.824       ‚ïë               ‚îÇ
‚îÇ  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù          ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù               ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó          ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó               ‚îÇ
‚îÇ  ‚ïë  Decision Tree        ‚ïë          ‚ïë  Decision Tree        ‚ïë               ‚îÇ
‚îÇ  ‚ïë  F1: 0.615            ‚ïë          ‚ïë  F1: 0.589            ‚ïë               ‚îÇ
‚îÇ  ‚ïë  ROC-AUC: 0.798       ‚ïë          ‚ïë  ROC-AUC: 0.772       ‚ïë               ‚îÇ
‚îÇ  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù          ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù               ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó          ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó               ‚îÇ
‚îÇ  ‚ïë  Random Forest  üèÜ    ‚ïë          ‚ïë  Random Forest  üèÜ    ‚ïë               ‚îÇ
‚îÇ  ‚ïë  F1: 0.745            ‚ïë          ‚ïë  F1: 0.712            ‚ïë               ‚îÇ
‚îÇ  ‚ïë  ROC-AUC: 0.902       ‚ïë          ‚ïë  ROC-AUC: 0.883       ‚ïë               ‚îÇ
‚îÇ  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù          ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù               ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó          ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó               ‚îÇ
‚îÇ  ‚ïë  SVM                  ‚ïë          ‚ïë  SVM                  ‚ïë               ‚îÇ
‚îÇ  ‚ïë  F1: 0.698            ‚ïë          ‚ïë  F1: 0.673            ‚ïë               ‚îÇ
‚îÇ  ‚ïë  ROC-AUC: 0.879       ‚ïë          ‚ïë  ROC-AUC: 0.854       ‚ïë               ‚îÇ
‚îÇ  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù          ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù               ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó          ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó               ‚îÇ
‚îÇ  ‚ïë  k-NN                 ‚ïë          ‚ïë  k-NN                 ‚ïë               ‚îÇ
‚îÇ  ‚ïë  F1: 0.642            ‚ïë          ‚ïë  F1: 0.615            ‚ïë               ‚îÇ
‚îÇ  ‚ïë  ROC-AUC: 0.821       ‚ïë          ‚ïë  ROC-AUC: 0.798       ‚ïë               ‚îÇ
‚îÇ  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù          ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù               ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó          ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó               ‚îÇ
‚îÇ  ‚ïë  XGBoost              ‚ïë          ‚ïë  XGBoost              ‚ïë               ‚îÇ
‚îÇ  ‚ïë  F1: 0.762            ‚ïë          ‚ïë  F1: 0.729            ‚ïë               ‚îÇ
‚îÇ  ‚ïë  ROC-AUC: 0.918       ‚ïë          ‚ïë  ROC-AUC: 0.897       ‚ïë               ‚îÇ
‚îÇ  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù          ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù               ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ          ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ            ‚îÇ
‚îÇ  Moyenne F1: 0.690                  Moyenne F1: 0.662                        ‚îÇ
‚îÇ  ‚ùå Surestim√© de ~2.8%               ‚úÖ Estimation r√©aliste                  ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ                     Diff√©rence: +2.8 points de pourcentage                   ‚îÇ
‚îÇ                     üö® DATA LEAKAGE MOD√âR√â d√©tect√©                           ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Note** : Les valeurs ci-dessus sont des estimations pour illustration. Les valeurs r√©elles seront g√©n√©r√©es lors de l'ex√©cution du notebook.

---

## üéØ Variables Cl√©s par Section

### Section 5 (Split Tardif)

```python
# Donn√©es pr√©par√©es
df_clean          # Apr√®s imputation (4410 lignes) - ‚ùå Leakage
df_encoded        # Apr√®s encodage (4410 lignes) - ‚ùå Leakage
X, y              # Features et target (4410 lignes)

# Apr√®s split
X_train, X_test           # (3528, ~40), (882, ~40)
y_train, y_test           # (3528,), (882,)

# Apr√®s transformations
X_train_scaled, X_test_scaled     # Standardis√©s
X_train_smote, y_train_smote      # Avec SMOTE (~6000 lignes)

# Mod√®les et r√©sultats
lr_model, lr_results, lr_pred, lr_proba      # Logistic Regression
dt_model, dt_results, dt_pred, dt_proba      # Decision Tree
rf_model, rf_results, rf_pred, rf_proba      # Random Forest
# ... (6 mod√®les au total)
```

### Section 5bis (Split Pr√©coce) - NOUVEAU

```python
# Donn√©es pr√©par√©es
df_split_precoce      # Copie de df_enriched (4410 lignes)
X_precoce, y_precoce  # Features et target AVANT split

# Split imm√©diat
X_train_precoce, X_test_precoce    # (3528, ~40), (882, ~40)
y_train_precoce, y_test_precoce    # (3528,), (882,)

# Transformateurs (ajust√©s sur train uniquement)
num_imputer           # SimpleImputer pour colonnes num√©riques
cat_imputer           # SimpleImputer pour colonnes cat√©gorielles
label_encoders_bp     # Dict de LabelEncoders
scaler_bp             # StandardScaler
smote_bp              # SMOTE

# Apr√®s transformations
X_train_bp, X_test_bp                 # Apr√®s imputation/encodage
X_train_bp_scaled, X_test_bp_scaled   # Apr√®s standardisation
X_train_bp_smote, y_train_bp_smote    # Avec SMOTE (~6000 lignes)

# Mod√®les et r√©sultats (suffix _bp pour "best practice")
lr_bp, lr_bp_results, lr_bp_pred, lr_bp_proba      # Logistic Regression
dt_bp, dt_bp_results, dt_bp_pred, dt_bp_proba      # Decision Tree
rf_bp, rf_bp_results, rf_bp_pred, rf_bp_proba      # Random Forest
svm_bp, svm_bp_results, svm_bp_pred, svm_bp_proba  # SVM
knn_bp, knn_bp_results, knn_bp_pred, knn_bp_proba  # k-NN
xgb_bp, xgb_bp_results, xgb_bp_pred, xgb_bp_proba  # XGBoost

# DataFrame de r√©sultats
results_split_precoce      # (6, 7) - Un DataFrame avec les 6 mod√®les
```

### Section 5ter (Comparaison) - NOUVEAU

```python
# Compilation des r√©sultats
results_split_tardif      # DataFrame (3-6 mod√®les depuis Section 6)
results_split_precoce     # DataFrame (6 mod√®les de Section 5bis)

# Comparaison
comparison_df   # DataFrame fusionnant les deux approches
                # Colonnes: Model, *_Tardif, *_Precoce, Diff_*, Diff_*_Pct

# M√©triques calcul√©es
avg_diff_f1     # Diff√©rence moyenne en F1-Score
avg_diff_roc    # Diff√©rence moyenne en ROC-AUC
```

---

## üîß Transformateurs et Leur R√¥le

### Imputation (Gestion des Valeurs Manquantes)

```python
from sklearn.impute import SimpleImputer

# ‚ùå MAUVAIS (Section 5)
imputer = SimpleImputer(strategy='median')
df_clean['Age'] = imputer.fit_transform(df[['Age']])  # FIT sur tout le dataset

# ‚úÖ BON (Section 5bis)
imputer = SimpleImputer(strategy='median')
X_train[['Age']] = imputer.fit_transform(X_train[['Age']])      # FIT sur train
X_test[['Age']] = imputer.transform(X_test[['Age']])            # TRANSFORM sur test
```

**Pourquoi c'est critique** :
- La m√©diane calcul√©e sur tout le dataset inclut des informations du test set
- En production, nous n'aurons JAMAIS acc√®s au test set complet
- La m√©diane doit √™tre calcul√©e sur les donn√©es d'entra√Ænement uniquement

---

### Encodage (Variables Cat√©gorielles)

```python
from sklearn.preprocessing import LabelEncoder

# ‚ùå MAUVAIS (Section 5)
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])  # FIT sur tout le dataset

# ‚úÖ BON (Section 5bis)
for col in categorical_cols:
    le = LabelEncoder()
    X_train[col] = le.fit_transform(X_train[col])  # FIT sur train uniquement
    
    # G√©rer les cat√©gories inconnues dans le test
    test_values = X_test[col].astype(str)
    unknown_mask = ~test_values.isin(le.classes_)
    
    if unknown_mask.sum() > 0:
        le.classes_ = np.append(le.classes_, 'Unknown')
        test_values[unknown_mask] = 'Unknown'
    
    X_test[col] = le.transform(test_values)  # TRANSFORM sur test
```

**Pourquoi c'est critique** :
- L'encodeur ne doit conna√Ætre que les cat√©gories du train
- En production, de nouvelles cat√©gories peuvent appara√Ætre
- Il faut g√©rer explicitement les cat√©gories inconnues

---

### Standardisation (Normalisation)

```python
from sklearn.preprocessing import StandardScaler

# ‚úÖ BON (les deux sections le font correctement)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)    # FIT sur train ‚Üí calcule mean/std
X_test_scaled = scaler.transform(X_test)          # TRANSFORM sur test ‚Üí utilise mean/std du train
```

**Pourquoi c'est OK dans les deux sections** :
- La Section 5 fait correctement cette √©tape (apr√®s le split)
- La Section 5bis aussi (conform√©ment au pipeline complet)

---

### SMOTE (R√©√©quilibrage)

```python
from imblearn.over_sampling import SMOTE

# ‚úÖ BON (les deux sections)
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)  # Train uniquement

# X_test reste INCHANG√â - garde la distribution naturelle (85% No, 15% Yes)
```

**Pourquoi appliquer SMOTE uniquement sur train** :
- Le test set doit refl√©ter la distribution r√©elle (d√©s√©quilibr√©e)
- R√©√©quilibrer le test fausserait l'√©valuation
- En production, les nouvelles donn√©es seront d√©s√©quilibr√©es

---

## üìà M√©triques d'√âvaluation

### M√©triques Calcul√©es pour Chaque Mod√®le

```python
# Train set (avec SMOTE, √©quilibr√© 50/50)
train_accuracy = accuracy_score(y_train_smote, y_pred_train)

# Test set (distribution naturelle 85/15)
test_accuracy = accuracy_score(y_test, y_pred_test)
precision = precision_score(y_test, y_pred_test)        # Combien de vrais positifs parmi les pr√©dits?
recall = recall_score(y_test, y_pred_test)              # Combien de vrais positifs d√©tect√©s?
f1 = f1_score(y_test, y_pred_test)                      # Moyenne harmonique precision/recall
roc_auc = roc_auc_score(y_test, y_pred_proba)           # Aire sous courbe ROC
```

### Interpr√©tation pour le Probl√®me d'Attrition

Dans le contexte RH (pr√©vention de l'attrition) :

- **Recall √©lev√© > Precision** : On pr√©f√®re d√©tecter tous les employ√©s √† risque (quitte √† avoir des faux positifs)
- **F1-Score** : √âquilibre global ‚Üí M√©trique principale de comparaison
- **ROC-AUC** : Capacit√© √† discriminer (insensible au seuil de d√©cision)

**Co√ªt de classification** :
- **Faux N√©gatif** (employ√© part, non d√©tect√©) ‚Üí CO√õT √âLEV√â (turnover co√ªteux)
- **Faux Positif** (employ√© reste, d√©tect√© √† risque) ‚Üí CO√õT FAIBLE (action de r√©tention inutile)

‚Üí **Privil√©gier le Recall** (d√©tecter tous les d√©parts)

---

## üöÄ Guide d'Ex√©cution Rapide

### 1. Pr√©requis
```bash
# Activer l'environnement virtuel
.venv\Scripts\Activate

# Installer les d√©pendances
pip install -r requirements.txt
```

### 2. Ex√©cution S√©quentielle (Recommand√©)
```
1. Ex√©cuter Sections 1 √† 4  ‚Üí  Pr√©pare df_enriched
2. Ex√©cuter Section 5       ‚Üí  Cr√©e donn√©es avec split tardif
3. Ex√©cuter Section 5bis    ‚Üí  Cr√©e donn√©es avec split pr√©coce ‚≠ê NOUVEAU
4. Ex√©cuter Section 6       ‚Üí  Mod√©lisation (split tardif)
5. Ex√©cuter Section 5ter    ‚Üí  Comparaison des approches ‚≠ê NOUVEAU
6. Analyser les r√©sultats   ‚Üí  Identifier le data leakage
```

### 3. Temps d'Ex√©cution Estim√©

| Section | Temps | Remarques |
|---------|-------|-----------|
| 1-3 | ~2 min | Setup, chargement, EDA |
| 4 | ~18 min | Feature extraction (time features) |
| 5 | ~30 sec | Pr√©paration split tardif |
| **5bis** | **~2-3 min** | **Pr√©paration split pr√©coce** ‚≠ê |
| 6 | ~5 min | Mod√©lisation (6 mod√®les) |
| **5ter** | **~1 min** | **Comparaison et visualisations** ‚≠ê |
| 7-10 | ~10 min | Optimisation, clustering, recommandations |

**Total** : ~39 minutes (avec les nouvelles sections)

---

## üìã Checklist de Validation Finale

### Avant Rendu du Projet

- [ ] **Notebook complet ex√©cut√©** (toutes les cellules)
- [ ] **Sections 5bis et 5ter pr√©sentes** et fonctionnelles
- [ ] **Comparaison visible** (tableau + visualisations)
- [ ] **Data leakage quantifi√©** (diff√©rence en F1-Score)
- [ ] **Recommandation claire** (utiliser split pr√©coce)
- [ ] **Interpr√©tation m√©thodologique** r√©dig√©e
- [ ] **Documentation compl√®te** (README, guides, etc.)
- [ ] **Code comment√©** abondamment
- [ ] **R√©sultats coh√©rents** (F1 entre 0.5-0.9)
- [ ] **Rapport final** int√®gre la comparaison m√©thodologique

---

## üéì Valeur P√©dagogique de l'Approche

### Ce Que D√©montre ce Projet

‚úÖ **Ma√Ætrise Technique**
- Impl√©mentation de 2 pipelines ML complets
- Application correcte de fit/transform
- Gestion de cas limites (cat√©gories inconnues)

‚úÖ **Esprit Critique**
- Identification proactive d'un probl√®me
- Remise en question du pipeline initial
- Validation empirique par comparaison

‚úÖ **Rigueur Scientifique**
- Comparaison quantitative (tableau, stats)
- Visualisations informatives
- Interpr√©tation prudente des r√©sultats

‚úÖ **Communication**
- Documentation exhaustive (3 guides)
- Code p√©dagogique (commentaires d√©taill√©s)
- Pr√©sentation claire des concepts

### Diff√©renciation par Rapport √† un Projet Standard

| Projet Standard | Votre Projet |
|----------------|-------------|
| 1 pipeline ML | 2 pipelines (comparaison) |
| Documentation basique | 3 guides complets |
| Ex√©cution simple | Analyse m√©thodologique approfondie |
| R√©sultats bruts | Interpr√©tation critique + le√ßons |
| Suit un tutoriel | Identifie et r√©sout des probl√®mes |

---

**Version** : 2.0  
**Date** : 19 f√©vrier 2026  
**Sections ajout√©es** : 5bis (28 cellules), 5ter (11 cellules)  
**Diff√©renciation** : Analyse comparative m√©thodologique - √âlimination du data leakage  
**Niveau** : √âcole d'Ing√©nieur - Projet avanc√©
