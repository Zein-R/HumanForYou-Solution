# ğŸ“˜ Guide d'Utilisation de la Section 5bis - Split PrÃ©coce (Best Practice)

## ğŸ¯ Objectif

La **Section 5bis** implÃ©mente les **best practices de Machine Learning** pour Ã©viter le **data leakage** lors de la prÃ©paration des donnÃ©es. Elle complÃ¨te la Section 5 originale et permet une comparaison mÃ©thodologique approfondie.

---

## ğŸ“Š Ce qui a Ã©tÃ© ajoutÃ© au notebook

### âœ… Section 5bis: PrÃ©paration des DonnÃ©es avec Split PrÃ©coce (Best Practice)

**41 nouvelles cellules** ajoutÃ©es entre la Section 5 et la Section 6, comprenant :

#### 1. Introduction et Explication (1 cellule Markdown)
- ProblÃ¨me mÃ©thodologique identifiÃ©
- Explication du data leakage
- Solution proposÃ©e (split prÃ©coce)

#### 2. Pipeline de PrÃ©paration (10 cellules)
- **Cellule 5bis.1** : Split immÃ©diat (AVANT toute transformation)
- **Cellule 5bis.2** : Imputation (FIT sur train, TRANSFORM sur test)
- **Cellule 5bis.3** : Encodage (FIT sur train, TRANSFORM sur test)
- **Cellule 5bis.4** : Standardisation (FIT sur train, TRANSFORM sur test)
- **Cellule 5bis.5** : SMOTE (train uniquement)
- **Cellule 5bis.6** : RÃ©capitulatif du pipeline

#### 3. EntraÃ®nement des ModÃ¨les (14 cellules)
- RÃ©gression Logistique
- Arbre de DÃ©cision
- Random Forest
- SVM (Support Vector Machine)
- k-NN (k-Nearest Neighbors)
- XGBoost
- Tableau rÃ©capitulatif des rÃ©sultats

#### 4. Section 5ter: Comparaison Split Tardif vs Split PrÃ©coce (11 cellules)
- PrÃ©paration des donnÃ©es de comparaison
- Tableau comparatif dÃ©taillÃ©
- 2 visualisations :
  * Comparaison des F1-Scores (barres)
  * Heatmap des diffÃ©rences
- Analyse statistique approfondie
- InterprÃ©tation et recommandations

---

## ğŸš€ Comment ExÃ©cuter la Section 5bis

### Option 1: ExÃ©cution SÃ©quentielle (RecommandÃ©)

1. **ExÃ©cuter toutes les cellules jusqu'Ã  la Section 5** (incluse)
   - Cela prÃ©pare `df_enriched` qui est nÃ©cessaire

2. **ExÃ©cuter la Section 5bis** cellule par cellule
   - Suivez l'ordre des cellules
   - Chaque cellule affiche des informations sur son traitement
   - **Temps estimÃ©** : 2-3 minutes pour toute la section

3. **ExÃ©cuter la Section 5ter (Comparaison)**
   - âš ï¸ **IMPORTANT** : Cette section nÃ©cessite que la Section 6 (modÃ©lisation originale) ait Ã©tÃ© exÃ©cutÃ©e pour crÃ©er les variables `lr_results`, `dt_results`, `rf_results`, etc.
   - Si ce n'est pas le cas, la section affichera un avertissement mais ne plantera pas

### Option 2: ExÃ©cution CiblÃ©e

Si vous avez dÃ©jÃ  exÃ©cutÃ© le notebook jusqu'Ã  la Section 6, vous pouvez :

1. **Re-exÃ©cuter la Section 5bis directement** (si `df_enriched` existe)
2. **ExÃ©cuter immÃ©diatement la Section 5ter** pour voir la comparaison

---

## ğŸ“ˆ RÃ©sultats Attendus

### A. Datasets CrÃ©Ã©s (Section 5bis)

| Dataset | Dimensions | Description | Utilisation |
|---------|------------|-------------|-------------|
| `X_train_precoce` | (~3500, ~40) | Features train (avant SMOTE) | Inspection |
| `X_test_precoce` | (~900, ~40) | Features test (avant transformations) | Inspection |
| `X_train_bp_smote` | (~6000, ~40) | Features train aprÃ¨s SMOTE | EntraÃ®nement |
| `X_test_bp_scaled` | (~900, ~40) | Features test standardisÃ©es | Ã‰valuation |
| `y_train_bp_smote` | (~6000,) | Target train Ã©quilibrÃ©e | EntraÃ®nement |
| `y_test_precoce` | (~900,) | Target test naturelle | Ã‰valuation |

### B. RÃ©sultats des ModÃ¨les (Section 5bis)

Un DataFrame `results_split_precoce` contenant :
- Model (nom du modÃ¨le)
- Train_Accuracy
- Test_Accuracy
- Precision
- Recall
- F1_Score â­ (mÃ©trique principale)
- ROC_AUC

**Exemple de rÃ©sultats attendus** :

```
                               Model  F1_Score  ROC_AUC
0  Logistic Regression (Split PrÃ©coce)   0.65     0.82
1       Decision Tree (Split PrÃ©coce)   0.58     0.78
2        Random Forest (Split PrÃ©coce)   0.71     0.88
3                 SVM (Split PrÃ©coce)   0.68     0.85
4                k-NN (Split PrÃ©coce)   0.63     0.80
5             XGBoost (Split PrÃ©coce)   0.73     0.90
```

### C. Comparaison (Section 5ter)

Un DataFrame `comparison_df` montrant :
- Performances Split Tardif (Section 5)
- Performances Split PrÃ©coce (Section 5bis)
- DiffÃ©rences (en points de pourcentage)
- DiffÃ©rences relatives (en %)

**InterprÃ©tation** :
- **DiffÃ©rence positive** (>2%) â†’ Data leakage dÃ©tectÃ© (Split Tardif surestimÃ©)
- **DiffÃ©rence proche de 0** (Â±1%) â†’ Pas de leakage significatif
- **DiffÃ©rence nÃ©gative** â†’ Split PrÃ©coce meilleur (rare, mais possible)

---

## ğŸ” Points ClÃ©s Ã  VÃ©rifier

### âœ… Checklist d'ExÃ©cution RÃ©ussie

- [ ] `df_enriched` existe avant d'exÃ©cuter la Section 5bis
- [ ] `X_train_bp_smote` a une forme ~(6000, 40) aprÃ¨s SMOTE
- [ ] `y_train_bp_smote` est Ã©quilibrÃ© (50/50)
- [ ] `X_test_bp_scaled` garde sa distribution naturelle
- [ ] `results_split_precoce` contient 6 lignes (6 modÃ¨les)
- [ ] Les F1-Scores sont entre 0.5 et 0.9 (valeurs rÃ©alistes)
- [ ] La comparaison affiche des diffÃ©rences < 5% en gÃ©nÃ©ral

### âš ï¸ ProblÃ¨mes Potentiels et Solutions

#### ProblÃ¨me 1: `NameError: name 'df_enriched' is not defined`
**Cause** : Section 4 (Feature Engineering) n'a pas Ã©tÃ© exÃ©cutÃ©e  
**Solution** : ExÃ©cuter toutes les cellules de la Section 4 qui crÃ©ent `df_enriched`

#### ProblÃ¨me 2: `NameError: name 'lr_results' is not defined` (Section 5ter)
**Cause** : Section 6 (modÃ©lisation originale) n'a pas encore Ã©tÃ© exÃ©cutÃ©e  
**Solution** : ExÃ©cuter la Section 6 d'abord, puis revenir Ã  la Section 5ter

#### ProblÃ¨me 3: `KeyError` avec des colonnes manquantes
**Cause** : Le dataset `df_enriched` ne contient pas les colonnes attendues  
**Solution** : VÃ©rifier que les cellules de fusion des datasets (Section 2) et de feature engineering (Section 4) ont bien Ã©tÃ© exÃ©cutÃ©es

#### ProblÃ¨me 4: Performances anormalement basses (<0.4 en F1-Score)
**Cause** : Encodage ou standardisation mal appliquÃ©s  
**Solution** : Re-exÃ©cuter la Section 5bis depuis le dÃ©but

---

## ğŸ“Š Analyse des RÃ©sultats

### A. Identifier le Data Leakage

**Calcul** :  
```python
diff_f1 = results_split_tardif['F1_Score'].mean() - results_split_precoce['F1_Score'].mean()
```

**InterprÃ©tation** :

| DiffÃ©rence (%) | Verdict | Action |
|----------------|---------|--------|
| > 3% | ğŸš¨ Data Leakage CRITIQUE | Utiliser UNIQUEMENT split prÃ©coce |
| 1-3% | âš ï¸ Data Leakage MODÃ‰RÃ‰ | PrÃ©fÃ©rer split prÃ©coce |
| 0-1% | âœ… Leakage NÃ‰GLIGEABLE | Split prÃ©coce par prÃ©caution |
| < 0% | âœ… Split PrÃ©coce MEILLEUR | Valider que c'est cohÃ©rent |

### B. ModÃ¨les les Plus Sensibles au Leakage

Les modÃ¨les les plus affectÃ©s par le data leakage sont gÃ©nÃ©ralement :
1. **k-NN** : TrÃ¨s sensible aux Ã©chelles et statistiques
2. **SVM** : DÃ©pend fortement de la standardisation
3. **RÃ©gression Logistique** : Sensible aux statistiques d'imputation

Les modÃ¨les robustes (moins affectÃ©s) :
1. **Random Forest** : GÃ¨re bien les donnÃ©es brutes
2. **XGBoost** : Robuste aux diffÃ©rences de prÃ©paration
3. **Arbres de DÃ©cision** : Moins sensibles aux Ã©chelles

---

## ğŸ’¡ LeÃ§ons Apprises

### 1. Le Timing du Split est CRUCIAL

**âŒ MAUVAIS** :  
```
DonnÃ©es â†’ Imputation â†’ Encodage â†’ Split â†’ Standardisation â†’ SMOTE
```
â†’ Data leakage aux Ã©tapes Imputation et Encodage

**âœ… BON** :  
```
DonnÃ©es â†’ Split â†’ Imputation â†’ Encodage â†’ Standardisation â†’ SMOTE
```
â†’ Aucun leakage

### 2. FIT vs TRANSFORM

**RÃˆGLE D'OR** :  
- **FIT** : Calculer les paramÃ¨tres (moyenne, mÃ©diane, classes, etc.) sur le **train set UNIQUEMENT**
- **TRANSFORM** : Appliquer ces paramÃ¨tres au **test set**

```python
# âœ… BON
imputer.fit(X_train)           # Calcule la mÃ©diane sur train
X_train = imputer.transform(X_train)
X_test = imputer.transform(X_test)  # Utilise la mÃ©diane du train

# âŒ MAUVAIS
imputer.fit(X)                 # Calcule sur train + test
X_train = imputer.transform(X_train)
X_test = imputer.transform(X_test)
```

### 3. SMOTE Uniquement sur Train

**POURQUOI** ? Le test set doit conserver sa distribution naturelle pour Ã©valuer les performances en conditions rÃ©elles.

```python
# âœ… BON
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
# X_test reste inchangÃ©

# âŒ MAUVAIS
X_smote, y_smote = smote.fit_resample(X, y)  # Sur tout le dataset
```

---

## ğŸ“ Pour Aller Plus Loin

### Questions Ã  Explorer

1. **Quelle est la diffÃ©rence de performance entre split tardif et prÃ©coce pour chaque modÃ¨le ?**
   - Analyser `comparison_df['Diff_F1_Score']`
   
2. **Quel modÃ¨le est le plus robuste au data leakage ?**
   - Identifier celui avec la plus petite diffÃ©rence
   
3. **Comment Ã©voluent les performances avec diffÃ©rents ratios de split ?**
   - Tester 70/30, 75/25, 85/15
   
4. **L'impact du leakage est-il plus important avec SMOTE ?**
   - Comparer avec et sans SMOTE

### ExpÃ©rimentations SuggÃ©rÃ©es

#### Exp. 1: Changer le Ratio de Split
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.3,  # Au lieu de 0.2
    random_state=42, 
    stratify=y
)
```

#### Exp. 2: Tester d'Autres StratÃ©gies d'Imputation
```python
# Imputation par rÃ©gression
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

imputer = IterativeImputer(random_state=42)
```

#### Exp. 3: Utiliser Pipeline de Sklearn
```python
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier())
])

pipeline.fit(X_train, y_train)  # Tout est appliquÃ© correctement
```

---

## ğŸ“ Conclusion

### Acquis MÃ©thodologiques

âœ… ComprÃ©hension du **data leakage** et de son impact  
âœ… MaÃ®trise du pipeline **fit/transform**  
âœ… Application des **best practices ML**  
âœ… CapacitÃ© Ã  **comparer et valider** des approches  
âœ… Esprit **critique et analytique** sur les rÃ©sultats  

### Recommandation Finale

**TOUJOURS utiliser l'approche Split PrÃ©coce** dans vos projets :
1. C'est la norme de l'industrie
2. Ã‰vite les mauvaises surprises en production
3. Donne des estimations honnÃªtes et fiables
4. DÃ©montre votre rigueur mÃ©thodologique

---

## ğŸ”— Ressources ComplÃ©mentaires

### Articles et Tutoriels
- [Avoiding Data Leakage in ML](https://machinelearningmastery.com/data-leakage-machine-learning/)
- [Sklearn Pipeline Best Practices](https://scikit-learn.org/stable/modules/compose.html)
- [Cross-Validation Done Right](https://towardsdatascience.com/cross-validation-done-right-7c9c3c5f0e48)

### Documentation Sklearn
- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)
- [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)
- [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)

---

**Date de crÃ©ation** : FÃ©vrier 2026  
**Version du notebook** : Employee_Attrition_Analysis.ipynb v2.0 (avec Section 5bis)  
**Auteur** : GitHub Copilot pour HumanForYou Analytics Team
